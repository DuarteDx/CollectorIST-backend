'use strict';

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.loadFileStream = exports.loadFile = exports.runMigrations = undefined;

let run = (() => {
  var _ref = _asyncToGenerator(function* ({ jobsPath, lockProvider, migrationPersistenceProvider }) {
    (0, _papagaio.logger)(['info', 'migration'], `Starting migration with ${migrationPersistenceProvider.constructor.name}`);
    let dbVersion = yield migrationPersistenceProvider.getDbVersion();
    if (!dbVersion) {
      (0, _papagaio.logger)(['info', 'migration'], 'Database is not initialized yet...');
    } else {
      (0, _papagaio.logger)(['info', 'migration'], `Database is in version ${dbVersion}`);
    }
    if (_fs2.default.existsSync(jobsPath)) {
      for (let filename of _fs2.default.readdirSync(jobsPath).sort()) {
        const version = Number(filename.split('-')[0]);
        const migration = require(_path2.default.join(jobsPath, filename));
        if (!migration.env || migration.env.includes(process.env.NODE_ENV)) {
          if (version > dbVersion) {
            (0, _papagaio.logger)(['info', 'migration'], `Running migration ${filename} because ${version} (Job Version) > ${dbVersion} (Current DB Version)`);
            yield migration.run();
            yield migrationPersistenceProvider.setDbVersion({ dbVersion: version });
            dbVersion = version;
          } else {
            (0, _papagaio.logger)(['info', 'migration'], `Skipping migration ${filename} because ${version} (Job Version) <= ${dbVersion} (Current DB Version)`);
          }
        }
      }
      (0, _papagaio.logger)(['info', 'migration'], `Migration finished successfully`);
    } else {
      (0, _papagaio.logger)(['info', 'porg', 'migrations'], 'Porg could not find any migrations folder.');
    }
  });

  return function run(_x) {
    return _ref.apply(this, arguments);
  };
})();

var _path = require('path');

var _path2 = _interopRequireDefault(_path);

var _fs = require('fs');

var _fs2 = _interopRequireDefault(_fs);

var _papagaio = require('papagaio');

var _providers = require('../providers');

var _utils = require('../utils');

var _JSONStream = require('JSONStream');

var _JSONStream2 = _interopRequireDefault(_JSONStream);

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function _asyncToGenerator(fn) { return function () { var gen = fn.apply(this, arguments); return new Promise(function (resolve, reject) { function step(key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { return Promise.resolve(value).then(function (value) { step("next", value); }, function (err) { step("throw", err); }); } } return step("next"); }); }; }

const MIGRATIONS_FOLDER = 'migrations/jobs';
let dirMainFile;


const runMigrations = (() => {
  var _ref2 = _asyncToGenerator(function* ({ lockProviderName, migrationPersistenceProviderName, applicationName, nodeStartPath }) {
    dirMainFile = _path2.default.dirname(require.main.filename);
    if (nodeStartPath) {
      dirMainFile = _path2.default.resolve(dirMainFile, nodeStartPath);
    }
    let normalizePath = _path2.default.join(dirMainFile, MIGRATIONS_FOLDER);
    let lockProvider = (0, _providers.getLockProvider)({ name: lockProviderName });
    let migrationPersistenceProvider = (0, _providers.getPersistenceMigrationProvider)({ name: migrationPersistenceProviderName });
    const session = yield lockProvider.createSession();
    const sessionRenewInterval = setInterval(function () {
      session.renewSession();
    }, 5000);
    while (!(yield session.attemptLock({ lockId: 'migrations' }))) {
      yield (0, _utils.sleep)(1000);
    }
    yield run({ jobsPath: normalizePath, lockProvider, migrationPersistenceProvider });
    session.releaseLock({ lockId: 'migrations' });
    session.destroySession();
    clearInterval(sessionRenewInterval);
  });

  return function runMigrations(_x2) {
    return _ref2.apply(this, arguments);
  };
})();
const loadFile = function ({ filename, pattern }) {
  let normalizePath = _path2.default.join(dirMainFile, 'migrations/data');
  (0, _papagaio.logger)(['info', 'migration', 'load-file'], `Environment: ${process.env.NODE_ENV}`);
  (0, _papagaio.logger)(['info', 'migration', 'load-file'], `Looking up ${filename}`);
  if (_fs2.default.existsSync(`${normalizePath}/${process.env.NODE_ENV}/${filename}`)) {
    (0, _papagaio.logger)(['info', 'migration', 'load-file'], `Loading file from ./data/${process.env.NODE_ENV}/${filename}`);
    return require(`${normalizePath}/${process.env.NODE_ENV}/${filename}`);
  } else {
    (0, _papagaio.logger)(['info', 'migration', 'load-file'], `Loading file from ./data/common/${filename}`);
    return require(`${normalizePath}/common/${filename}`);
  }
};

const loadFileStream = function ({ filename, pattern }) {
  let normalizePath = _path2.default.join(dirMainFile, 'migrations/data');
  (0, _papagaio.logger)(['info', 'migration', 'load-file'], `Environment: ${process.env.NODE_ENV}`);
  (0, _papagaio.logger)(['info', 'migration', 'load-file'], `Looking up ${filename}`);
  if (_fs2.default.existsSync(`${normalizePath}/${process.env.NODE_ENV}/${filename}`)) {
    (0, _papagaio.logger)(['info', 'migration', 'load-file'], `Loading file from ./data/${process.env.NODE_ENV}/${filename}`);
    return parseJsonFile({ path: `${normalizePath}/${process.env.NODE_ENV}/${filename}`, pattern });
  } else {
    (0, _papagaio.logger)(['info', 'migration', 'load-file'], `Loading file from ./data/common/${filename}`);
    return parseJsonFile({ path: `${normalizePath}/common/${filename}`, pattern });
  }
};

function parseJsonFile({ path, pattern }) {
  pattern = pattern || '*';
  const stream = _fs2.default.createReadStream(path, { encoding: 'utf8' });
  const parser = _JSONStream2.default.parse(pattern);
  stream.pipe(parser);
  return parser;
}

exports.runMigrations = runMigrations;
exports.loadFile = loadFile;
exports.loadFileStream = loadFileStream;